Using scheduler:  True
Train data: 14000
Valid data: 3000
Test data: 3000
initializing ensemble model
Epoch 0 train loss: 0.6750 acc: 0.5999 lr: 2.132e-07
Epoch 0 valid loss: 0.6723 acc: 0.6010
Saving Best
Epoch 1 train loss: 0.6715 acc: 0.6101 lr: 2.525e-07
Epoch 1 valid loss: 0.6709 acc: 0.6090
Saving Best
Epoch 2 train loss: 0.6694 acc: 0.6153 lr: 3.176e-07
Epoch 2 valid loss: 0.6665 acc: 0.6107
Saving Best
Epoch 3 train loss: 0.6668 acc: 0.6218 lr: 4.077e-07
Epoch 3 valid loss: 0.6655 acc: 0.6283
Saving Best
Epoch 4 train loss: 0.6629 acc: 0.6374 lr: 5.219e-07
Epoch 4 valid loss: 0.6613 acc: 0.6430
Saving Best
Epoch 5 train loss: 0.6579 acc: 0.6559 lr: 6.589e-07
Epoch 5 valid loss: 0.6559 acc: 0.6540
Saving Best
Epoch 6 train loss: 0.6522 acc: 0.6665 lr: 8.172e-07
Epoch 6 valid loss: 0.6498 acc: 0.6790
Saving Best
Epoch 7 train loss: 0.6445 acc: 0.6893 lr: 9.95e-07
Epoch 7 valid loss: 0.6426 acc: 0.6850
Saving Best
Epoch 8 train loss: 0.6366 acc: 0.7100 lr: 1.19e-06
Epoch 8 valid loss: 0.6312 acc: 0.7197
Saving Best
Epoch 9 train loss: 0.6272 acc: 0.7318 lr: 1.401e-06
Epoch 9 valid loss: 0.6196 acc: 0.7467
Saving Best
Epoch 10 train loss: 0.6161 acc: 0.7544 lr: 1.625e-06
Epoch 10 valid loss: 0.6113 acc: 0.7637
Saving Best
Epoch 11 train loss: 0.6039 acc: 0.7711 lr: 1.86e-06
Epoch 11 valid loss: 0.5988 acc: 0.7747
Saving Best
Epoch 12 train loss: 0.5908 acc: 0.7946 lr: 2.103e-06
Epoch 12 valid loss: 0.5839 acc: 0.8037
Saving Best
Epoch 13 train loss: 0.5768 acc: 0.8061 lr: 2.351e-06
Epoch 13 valid loss: 0.5709 acc: 0.8140
Saving Best
Epoch 14 train loss: 0.5630 acc: 0.8144 lr: 2.602e-06
Epoch 14 valid loss: 0.5556 acc: 0.8230
Saving Best
Epoch 15 train loss: 0.5482 acc: 0.8226 lr: 2.853e-06
Epoch 15 valid loss: 0.5411 acc: 0.8297
Saving Best
Epoch 16 train loss: 0.5340 acc: 0.8301 lr: 3.102e-06
Epoch 16 valid loss: 0.5267 acc: 0.8360
Saving Best
Epoch 17 train loss: 0.5181 acc: 0.8349 lr: 3.344e-06
Epoch 17 valid loss: 0.5131 acc: 0.8387
Saving Best
Epoch 18 train loss: 0.5037 acc: 0.8370 lr: 3.579e-06
Epoch 18 valid loss: 0.4969 acc: 0.8387
Epoch 19 train loss: 0.4900 acc: 0.8401 lr: 3.803e-06
Epoch 19 valid loss: 0.4824 acc: 0.8433
Saving Best
Epoch 20 train loss: 0.4748 acc: 0.8419 lr: 4.013e-06
Epoch 20 valid loss: 0.4683 acc: 0.8463
Saving Best
Epoch 21 train loss: 0.4623 acc: 0.8445 lr: 4.208e-06
Epoch 21 valid loss: 0.4590 acc: 0.8457
Epoch 22 train loss: 0.4495 acc: 0.8468 lr: 4.386e-06
Epoch 22 valid loss: 0.4444 acc: 0.8440
Epoch 23 train loss: 0.4369 acc: 0.8472 lr: 4.544e-06
Epoch 23 valid loss: 0.4346 acc: 0.8423
Epoch 24 train loss: 0.4269 acc: 0.8473 lr: 4.68e-06
Epoch 24 valid loss: 0.4218 acc: 0.8443
Epoch 25 train loss: 0.4172 acc: 0.8506 lr: 4.794e-06
Epoch 25 valid loss: 0.4140 acc: 0.8483
Saving Best
Epoch 26 train loss: 0.4071 acc: 0.8505 lr: 4.884e-06
Epoch 26 valid loss: 0.4032 acc: 0.8473
Epoch 27 train loss: 0.3993 acc: 0.8521 lr: 4.948e-06
Epoch 27 valid loss: 0.3952 acc: 0.8517
Saving Best
Epoch 28 train loss: 0.3919 acc: 0.8509 lr: 4.987e-06
Epoch 28 valid loss: 0.3900 acc: 0.8520
Saving Best
Epoch 29 train loss: 0.3852 acc: 0.8522 lr: 5e-06
Epoch 29 valid loss: 0.3817 acc: 0.8490
Epoch 30 train loss: 0.3792 acc: 0.8525 lr: 4.997e-06
Epoch 30 valid loss: 0.3761 acc: 0.8503
Epoch 31 train loss: 0.3737 acc: 0.8527 lr: 4.99e-06
Epoch 31 valid loss: 0.3721 acc: 0.8477
Epoch 32 train loss: 0.3683 acc: 0.8526 lr: 4.977e-06
Epoch 32 valid loss: 0.3673 acc: 0.8483
Epoch 33 train loss: 0.3648 acc: 0.8532 lr: 4.959e-06
Epoch 33 valid loss: 0.3628 acc: 0.8517
Epoch 34 train loss: 0.3604 acc: 0.8531 lr: 4.937e-06
Epoch 34 valid loss: 0.3614 acc: 0.8513
Epoch 35 train loss: 0.3576 acc: 0.8528 lr: 4.909e-06
Epoch 35 valid loss: 0.3561 acc: 0.8470
Epoch 36 train loss: 0.3543 acc: 0.8534 lr: 4.877e-06
Epoch 36 valid loss: 0.3528 acc: 0.8517
Epoch 37 train loss: 0.3526 acc: 0.8537 lr: 4.84e-06
Epoch 37 valid loss: 0.3515 acc: 0.8500
Epoch 38 train loss: 0.3490 acc: 0.8535 lr: 4.798e-06
Epoch 38 valid loss: 0.3476 acc: 0.8483
Epoch 39 train loss: 0.3468 acc: 0.8544 lr: 4.752e-06
Epoch 39 valid loss: 0.3467 acc: 0.8493
Epoch 40 train loss: 0.3465 acc: 0.8546 lr: 4.701e-06
Epoch 40 valid loss: 0.3452 acc: 0.8487
Epoch 41 train loss: 0.3447 acc: 0.8531 lr: 4.645e-06
Epoch 41 valid loss: 0.3423 acc: 0.8503
Epoch 42 train loss: 0.3441 acc: 0.8543 lr: 4.585e-06
Epoch 42 valid loss: 0.3446 acc: 0.8517
Epoch 43 train loss: 0.3403 acc: 0.8548 lr: 4.521e-06
Epoch 43 valid loss: 0.3430 acc: 0.8503
Epoch 44 train loss: 0.3398 acc: 0.8548 lr: 4.453e-06
Epoch 44 valid loss: 0.3405 acc: 0.8533
Saving Best
Epoch 45 train loss: 0.3407 acc: 0.8557 lr: 4.381e-06
Epoch 45 valid loss: 0.3393 acc: 0.8513
Epoch 46 train loss: 0.3393 acc: 0.8560 lr: 4.306e-06
Epoch 46 valid loss: 0.3392 acc: 0.8517
Epoch 47 train loss: 0.3367 acc: 0.8544 lr: 4.226e-06
Epoch 47 valid loss: 0.3391 acc: 0.8507
Epoch 48 train loss: 0.3380 acc: 0.8544 lr: 4.143e-06
Epoch 48 valid loss: 0.3395 acc: 0.8503
Epoch 49 train loss: 0.3359 acc: 0.8546 lr: 4.057e-06
Epoch 49 valid loss: 0.3405 acc: 0.8510
Epoch 50 train loss: 0.3352 acc: 0.8556 lr: 3.968e-06
Epoch 50 valid loss: 0.3395 acc: 0.8497
Epoch 51 train loss: 0.3355 acc: 0.8542 lr: 3.876e-06
Epoch 51 valid loss: 0.3355 acc: 0.8490
Epoch 52 train loss: 0.3353 acc: 0.8557 lr: 3.781e-06
Epoch 52 valid loss: 0.3318 acc: 0.8507
Epoch 53 train loss: 0.3351 acc: 0.8554 lr: 3.683e-06
Epoch 53 valid loss: 0.3363 acc: 0.8530
Epoch 54 train loss: 0.3353 acc: 0.8565 lr: 3.583e-06
Epoch 54 valid loss: 0.3354 acc: 0.8493
Epoch 55 train loss: 0.3348 acc: 0.8554 lr: 3.481e-06
Epoch 55 valid loss: 0.3332 acc: 0.8513
Epoch 56 train loss: 0.3349 acc: 0.8548 lr: 3.377e-06
Epoch 56 valid loss: 0.3347 acc: 0.8497
Epoch 57 train loss: 0.3329 acc: 0.8564 lr: 3.271e-06
Epoch 57 valid loss: 0.3328 acc: 0.8503
Epoch 58 train loss: 0.3340 acc: 0.8543 lr: 3.163e-06
Epoch 58 valid loss: 0.3311 acc: 0.8520
Epoch 59 train loss: 0.3331 acc: 0.8566 lr: 3.054e-06
Epoch 59 valid loss: 0.3350 acc: 0.8510
Epoch 60 train loss: 0.3317 acc: 0.8551 lr: 2.944e-06
Epoch 60 valid loss: 0.3303 acc: 0.8523
Epoch 61 train loss: 0.3323 acc: 0.8556 lr: 2.834e-06
Epoch 61 valid loss: 0.3348 acc: 0.8490
Epoch 62 train loss: 0.3334 acc: 0.8569 lr: 2.722e-06
Epoch 62 valid loss: 0.3308 acc: 0.8500
Epoch 63 train loss: 0.3335 acc: 0.8556 lr: 2.61e-06
Epoch 63 valid loss: 0.3311 acc: 0.8510
Epoch 64 train loss: 0.3315 acc: 0.8564 lr: 2.498e-06
Epoch 64 valid loss: 0.3323 acc: 0.8513
Epoch 65 train loss: 0.3325 acc: 0.8552 lr: 2.386e-06
Epoch 65 valid loss: 0.3315 acc: 0.8530
Epoch 66 train loss: 0.3334 acc: 0.8561 lr: 2.274e-06
Epoch 66 valid loss: 0.3328 acc: 0.8523
Epoch 67 train loss: 0.3320 acc: 0.8564 lr: 2.162e-06
Epoch 67 valid loss: 0.3346 acc: 0.8480
Epoch 68 train loss: 0.3319 acc: 0.8556 lr: 2.052e-06
Epoch 68 valid loss: 0.3337 acc: 0.8510
Epoch 69 train loss: 0.3327 acc: 0.8553 lr: 1.942e-06
Epoch 69 valid loss: 0.3341 acc: 0.8520
Epoch 70 train loss: 0.3327 acc: 0.8559 lr: 1.833e-06
Epoch 70 valid loss: 0.3313 acc: 0.8503
Epoch 71 train loss: 0.3315 acc: 0.8559 lr: 1.726e-06
Epoch 71 valid loss: 0.3305 acc: 0.8510
Epoch 72 train loss: 0.3311 acc: 0.8567 lr: 1.62e-06
Epoch 72 valid loss: 0.3322 acc: 0.8510
Epoch 73 train loss: 0.3322 acc: 0.8553 lr: 1.516e-06
Epoch 73 valid loss: 0.3322 acc: 0.8513
Epoch 74 train loss: 0.3332 acc: 0.8559 lr: 1.413e-06
Epoch 74 valid loss: 0.3329 acc: 0.8507
Epoch 75 train loss: 0.3325 acc: 0.8563 lr: 1.314e-06
Epoch 75 valid loss: 0.3326 acc: 0.8510
Epoch 76 train loss: 0.3324 acc: 0.8555 lr: 1.216e-06
Epoch 76 valid loss: 0.3340 acc: 0.8507
Epoch 77 train loss: 0.3315 acc: 0.8556 lr: 1.121e-06
Epoch 77 valid loss: 0.3312 acc: 0.8507
Epoch 78 train loss: 0.3332 acc: 0.8562 lr: 1.029e-06
Epoch 78 valid loss: 0.3310 acc: 0.8527
Epoch 79 train loss: 0.3323 acc: 0.8550 lr: 9.397e-07
Epoch 79 valid loss: 0.3311 acc: 0.8510
Epoch 80 train loss: 0.3307 acc: 0.8556 lr: 8.536e-07
Epoch 80 valid loss: 0.3358 acc: 0.8483
Epoch 81 train loss: 0.3323 acc: 0.8559 lr: 7.709e-07
Epoch 81 valid loss: 0.3327 acc: 0.8520
Epoch 82 train loss: 0.3321 acc: 0.8554 lr: 6.916e-07
Epoch 82 valid loss: 0.3323 acc: 0.8523
Epoch 83 train loss: 0.3328 acc: 0.8569 lr: 6.16e-07
Epoch 83 valid loss: 0.3303 acc: 0.8507
Epoch 84 train loss: 0.3321 acc: 0.8565 lr: 5.442e-07
Epoch 84 valid loss: 0.3337 acc: 0.8477
Epoch 85 train loss: 0.3316 acc: 0.8572 lr: 4.763e-07
Epoch 85 valid loss: 0.3340 acc: 0.8500
Epoch 86 train loss: 0.3307 acc: 0.8556 lr: 4.125e-07
Epoch 86 valid loss: 0.3320 acc: 0.8523
Epoch 87 train loss: 0.3306 acc: 0.8559 lr: 3.529e-07
Epoch 87 valid loss: 0.3317 acc: 0.8497
Epoch 88 train loss: 0.3319 acc: 0.8556 lr: 2.976e-07
Epoch 88 valid loss: 0.3318 acc: 0.8520
Epoch 89 train loss: 0.3329 acc: 0.8548 lr: 2.467e-07
Epoch 89 valid loss: 0.3338 acc: 0.8510
Epoch 90 train loss: 0.3330 acc: 0.8561 lr: 2.004e-07
Epoch 90 valid loss: 0.3300 acc: 0.8490
Epoch 91 train loss: 0.3323 acc: 0.8558 lr: 1.587e-07
Epoch 91 valid loss: 0.3325 acc: 0.8497
Epoch 92 train loss: 0.3313 acc: 0.8554 lr: 1.217e-07
Epoch 92 valid loss: 0.3301 acc: 0.8513
Epoch 93 train loss: 0.3329 acc: 0.8571 lr: 8.957e-08
Epoch 93 valid loss: 0.3354 acc: 0.8507
Epoch 94 train loss: 0.3332 acc: 0.8561 lr: 6.225e-08
Epoch 94 valid loss: 0.3345 acc: 0.8517
Epoch 95 train loss: 0.3320 acc: 0.8565 lr: 3.983e-08
Epoch 95 valid loss: 0.3322 acc: 0.8513
Epoch 96 train loss: 0.3316 acc: 0.8552 lr: 2.237e-08
Epoch 96 valid loss: 0.3301 acc: 0.8513
Epoch 97 train loss: 0.3322 acc: 0.8561 lr: 9.902e-09
Epoch 97 valid loss: 0.3304 acc: 0.8500
Epoch 98 train loss: 0.3325 acc: 0.8554 lr: 2.447e-09
Epoch 98 valid loss: 0.3334 acc: 0.8503
Epoch 99 train loss: 0.3318 acc: 0.8561 lr: 2.083e-11
Epoch 99 valid loss: 0.3360 acc: 0.8510
Training Time: 1617.0252952575684
Training Peak Mem: 946.95703125
Training Params: 60544
Testing: synthetic/experiments/redundancy/redundancy_ensemble_best.pt
loss: tensor(0.3508, device='cuda:0')
acc: 0.8486666666666667
