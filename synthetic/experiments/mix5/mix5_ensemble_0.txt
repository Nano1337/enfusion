Using scheduler:  True
Train data: 14000
Valid data: 3000
Test data: 3000
initializing ensemble model
Epoch 0 train loss: 0.6920 acc: 0.5526 lr: 2.132e-07
Epoch 0 valid loss: 0.6933 acc: 0.5620
Saving Best
Epoch 1 train loss: 0.6903 acc: 0.5591 lr: 2.525e-07
Epoch 1 valid loss: 0.6913 acc: 0.5470
Epoch 2 train loss: 0.6895 acc: 0.5597 lr: 3.176e-07
Epoch 2 valid loss: 0.6879 acc: 0.5653
Saving Best
Epoch 3 train loss: 0.6874 acc: 0.5658 lr: 4.077e-07
Epoch 3 valid loss: 0.6871 acc: 0.5637
Epoch 4 train loss: 0.6848 acc: 0.5782 lr: 5.219e-07
Epoch 4 valid loss: 0.6845 acc: 0.5773
Saving Best
Epoch 5 train loss: 0.6815 acc: 0.5845 lr: 6.589e-07
Epoch 5 valid loss: 0.6810 acc: 0.5960
Saving Best
Epoch 6 train loss: 0.6788 acc: 0.5960 lr: 8.172e-07
Epoch 6 valid loss: 0.6750 acc: 0.6140
Saving Best
Epoch 7 train loss: 0.6731 acc: 0.6059 lr: 9.95e-07
Epoch 7 valid loss: 0.6696 acc: 0.6277
Saving Best
Epoch 8 train loss: 0.6682 acc: 0.6227 lr: 1.19e-06
Epoch 8 valid loss: 0.6649 acc: 0.6407
Saving Best
Epoch 9 train loss: 0.6633 acc: 0.6341 lr: 1.401e-06
Epoch 9 valid loss: 0.6593 acc: 0.6457
Saving Best
Epoch 10 train loss: 0.6569 acc: 0.6484 lr: 1.625e-06
Epoch 10 valid loss: 0.6505 acc: 0.6683
Saving Best
Epoch 11 train loss: 0.6509 acc: 0.6548 lr: 1.86e-06
Epoch 11 valid loss: 0.6444 acc: 0.6720
Saving Best
Epoch 12 train loss: 0.6440 acc: 0.6625 lr: 2.103e-06
Epoch 12 valid loss: 0.6392 acc: 0.6777
Saving Best
Epoch 13 train loss: 0.6384 acc: 0.6716 lr: 2.351e-06
Epoch 13 valid loss: 0.6338 acc: 0.6810
Saving Best
Epoch 14 train loss: 0.6324 acc: 0.6768 lr: 2.602e-06
Epoch 14 valid loss: 0.6296 acc: 0.6820
Saving Best
Epoch 15 train loss: 0.6265 acc: 0.6800 lr: 2.853e-06
Epoch 15 valid loss: 0.6217 acc: 0.6913
Saving Best
Epoch 16 train loss: 0.6209 acc: 0.6833 lr: 3.102e-06
Epoch 16 valid loss: 0.6171 acc: 0.6900
Epoch 17 train loss: 0.6163 acc: 0.6891 lr: 3.344e-06
Epoch 17 valid loss: 0.6122 acc: 0.6950
Saving Best
Epoch 18 train loss: 0.6121 acc: 0.6903 lr: 3.579e-06
Epoch 18 valid loss: 0.6075 acc: 0.7030
Saving Best
Epoch 19 train loss: 0.6097 acc: 0.6931 lr: 3.803e-06
Epoch 19 valid loss: 0.6046 acc: 0.6980
Epoch 20 train loss: 0.6063 acc: 0.6923 lr: 4.013e-06
Epoch 20 valid loss: 0.6010 acc: 0.6993
Epoch 21 train loss: 0.6052 acc: 0.6951 lr: 4.208e-06
Epoch 21 valid loss: 0.6005 acc: 0.7030
Epoch 22 train loss: 0.6011 acc: 0.6972 lr: 4.386e-06
Epoch 22 valid loss: 0.6002 acc: 0.7037
Saving Best
Epoch 23 train loss: 0.6009 acc: 0.7014 lr: 4.544e-06
Epoch 23 valid loss: 0.5976 acc: 0.7023
Epoch 24 train loss: 0.5988 acc: 0.7032 lr: 4.68e-06
Epoch 24 valid loss: 0.5942 acc: 0.7020
Epoch 25 train loss: 0.5993 acc: 0.7014 lr: 4.794e-06
Epoch 25 valid loss: 0.5928 acc: 0.7080
Saving Best
Epoch 26 train loss: 0.5978 acc: 0.7041 lr: 4.884e-06
Epoch 26 valid loss: 0.5940 acc: 0.7017
Epoch 27 train loss: 0.5968 acc: 0.7036 lr: 4.948e-06
Epoch 27 valid loss: 0.5963 acc: 0.6980
Epoch 28 train loss: 0.5979 acc: 0.7042 lr: 4.987e-06
Epoch 28 valid loss: 0.5946 acc: 0.7030
Epoch 29 train loss: 0.5951 acc: 0.7062 lr: 5e-06
Epoch 29 valid loss: 0.5935 acc: 0.7067
Epoch 30 train loss: 0.5959 acc: 0.7035 lr: 4.997e-06
Epoch 30 valid loss: 0.5927 acc: 0.7027
Epoch 31 train loss: 0.5957 acc: 0.7081 lr: 4.99e-06
Epoch 31 valid loss: 0.5939 acc: 0.7077
Epoch 32 train loss: 0.5964 acc: 0.7068 lr: 4.977e-06
Epoch 32 valid loss: 0.5928 acc: 0.7093
Saving Best
Epoch 33 train loss: 0.5967 acc: 0.7034 lr: 4.959e-06
Epoch 33 valid loss: 0.5926 acc: 0.7087
Epoch 34 train loss: 0.5957 acc: 0.7047 lr: 4.937e-06
Epoch 34 valid loss: 0.5925 acc: 0.7083
Epoch 35 train loss: 0.5948 acc: 0.7066 lr: 4.909e-06
Epoch 35 valid loss: 0.5913 acc: 0.7047
Epoch 36 train loss: 0.5961 acc: 0.7066 lr: 4.877e-06
Epoch 36 valid loss: 0.5906 acc: 0.7033
Epoch 37 train loss: 0.5963 acc: 0.7066 lr: 4.84e-06
Epoch 37 valid loss: 0.5916 acc: 0.7083
Epoch 38 train loss: 0.5958 acc: 0.7046 lr: 4.798e-06
Epoch 38 valid loss: 0.5895 acc: 0.7063
Epoch 39 train loss: 0.5964 acc: 0.7053 lr: 4.752e-06
Epoch 39 valid loss: 0.5908 acc: 0.7063
Epoch 40 train loss: 0.5960 acc: 0.7061 lr: 4.701e-06
Epoch 40 valid loss: 0.5904 acc: 0.7087
Epoch 41 train loss: 0.5944 acc: 0.7042 lr: 4.645e-06
Epoch 41 valid loss: 0.5897 acc: 0.7083
Epoch 42 train loss: 0.5955 acc: 0.7070 lr: 4.585e-06
Epoch 42 valid loss: 0.5896 acc: 0.7103
Saving Best
Epoch 43 train loss: 0.5951 acc: 0.7069 lr: 4.521e-06
Epoch 43 valid loss: 0.5929 acc: 0.7030
Epoch 44 train loss: 0.5937 acc: 0.7061 lr: 4.453e-06
Epoch 44 valid loss: 0.5902 acc: 0.7023
Epoch 45 train loss: 0.5940 acc: 0.7081 lr: 4.381e-06
Epoch 45 valid loss: 0.5918 acc: 0.7063
Epoch 46 train loss: 0.5937 acc: 0.7076 lr: 4.306e-06
Epoch 46 valid loss: 0.5887 acc: 0.7070
Epoch 47 train loss: 0.5946 acc: 0.7064 lr: 4.226e-06
Epoch 47 valid loss: 0.5903 acc: 0.7060
Epoch 48 train loss: 0.5954 acc: 0.7081 lr: 4.143e-06
Epoch 48 valid loss: 0.5904 acc: 0.7100
Epoch 49 train loss: 0.5932 acc: 0.7066 lr: 4.057e-06
Epoch 49 valid loss: 0.5884 acc: 0.7063
Epoch 50 train loss: 0.5944 acc: 0.7066 lr: 3.968e-06
Epoch 50 valid loss: 0.5905 acc: 0.7030
Epoch 51 train loss: 0.5921 acc: 0.7069 lr: 3.876e-06
Epoch 51 valid loss: 0.5922 acc: 0.7027
Epoch 52 train loss: 0.5942 acc: 0.7074 lr: 3.781e-06
Epoch 52 valid loss: 0.5925 acc: 0.7117
Saving Best
Epoch 53 train loss: 0.5959 acc: 0.7044 lr: 3.683e-06
Epoch 53 valid loss: 0.5931 acc: 0.7023
Epoch 54 train loss: 0.5940 acc: 0.7075 lr: 3.583e-06
Epoch 54 valid loss: 0.5915 acc: 0.7040
Epoch 55 train loss: 0.5941 acc: 0.7081 lr: 3.481e-06
Epoch 55 valid loss: 0.5889 acc: 0.7050
Epoch 56 train loss: 0.5940 acc: 0.7092 lr: 3.377e-06
Epoch 56 valid loss: 0.5911 acc: 0.7087
Epoch 57 train loss: 0.5938 acc: 0.7078 lr: 3.271e-06
Epoch 57 valid loss: 0.5906 acc: 0.7073
Epoch 58 train loss: 0.5924 acc: 0.7094 lr: 3.163e-06
Epoch 58 valid loss: 0.5946 acc: 0.7057
Epoch 59 train loss: 0.5938 acc: 0.7071 lr: 3.054e-06
Epoch 59 valid loss: 0.5903 acc: 0.7047
Epoch 60 train loss: 0.5934 acc: 0.7078 lr: 2.944e-06
Epoch 60 valid loss: 0.5922 acc: 0.7057
Epoch 61 train loss: 0.5946 acc: 0.7074 lr: 2.834e-06
Epoch 61 valid loss: 0.5899 acc: 0.7070
Epoch 62 train loss: 0.5929 acc: 0.7105 lr: 2.722e-06
Epoch 62 valid loss: 0.5903 acc: 0.7070
Epoch 63 train loss: 0.5934 acc: 0.7094 lr: 2.61e-06
Epoch 63 valid loss: 0.5934 acc: 0.7070
Epoch 64 train loss: 0.5943 acc: 0.7081 lr: 2.498e-06
Epoch 64 valid loss: 0.5935 acc: 0.7090
Epoch 65 train loss: 0.5936 acc: 0.7098 lr: 2.386e-06
Epoch 65 valid loss: 0.5891 acc: 0.7117
Epoch 66 train loss: 0.5937 acc: 0.7086 lr: 2.274e-06
Epoch 66 valid loss: 0.5900 acc: 0.7070
Epoch 67 train loss: 0.5938 acc: 0.7091 lr: 2.162e-06
Epoch 67 valid loss: 0.5896 acc: 0.7043
Epoch 68 train loss: 0.5933 acc: 0.7109 lr: 2.052e-06
Epoch 68 valid loss: 0.5907 acc: 0.7117
Epoch 69 train loss: 0.5925 acc: 0.7094 lr: 1.942e-06
Epoch 69 valid loss: 0.5912 acc: 0.7073
Epoch 70 train loss: 0.5931 acc: 0.7084 lr: 1.833e-06
Epoch 70 valid loss: 0.5892 acc: 0.7097
Epoch 71 train loss: 0.5933 acc: 0.7100 lr: 1.726e-06
Epoch 71 valid loss: 0.5916 acc: 0.7100
Epoch 72 train loss: 0.5932 acc: 0.7087 lr: 1.62e-06
Epoch 72 valid loss: 0.5888 acc: 0.7030
Epoch 73 train loss: 0.5920 acc: 0.7098 lr: 1.516e-06
Epoch 73 valid loss: 0.5895 acc: 0.7070
Epoch 74 train loss: 0.5921 acc: 0.7075 lr: 1.413e-06
Epoch 74 valid loss: 0.5907 acc: 0.7127
Saving Best
Epoch 75 train loss: 0.5928 acc: 0.7084 lr: 1.314e-06
Epoch 75 valid loss: 0.5901 acc: 0.7107
Epoch 76 train loss: 0.5929 acc: 0.7094 lr: 1.216e-06
Epoch 76 valid loss: 0.5911 acc: 0.7077
Epoch 77 train loss: 0.5931 acc: 0.7107 lr: 1.121e-06
Epoch 77 valid loss: 0.5886 acc: 0.7073
Epoch 78 train loss: 0.5932 acc: 0.7057 lr: 1.029e-06
Epoch 78 valid loss: 0.5911 acc: 0.7103
Epoch 79 train loss: 0.5930 acc: 0.7071 lr: 9.397e-07
Epoch 79 valid loss: 0.5908 acc: 0.7077
Epoch 80 train loss: 0.5946 acc: 0.7078 lr: 8.536e-07
Epoch 80 valid loss: 0.5882 acc: 0.7053
Epoch 81 train loss: 0.5936 acc: 0.7091 lr: 7.709e-07
Epoch 81 valid loss: 0.5910 acc: 0.7107
Epoch 82 train loss: 0.5933 acc: 0.7086 lr: 6.916e-07
Epoch 82 valid loss: 0.5895 acc: 0.7050
Epoch 83 train loss: 0.5934 acc: 0.7078 lr: 6.16e-07
Epoch 83 valid loss: 0.5907 acc: 0.7080
Epoch 84 train loss: 0.5920 acc: 0.7109 lr: 5.442e-07
Epoch 84 valid loss: 0.5883 acc: 0.7077
Epoch 85 train loss: 0.5934 acc: 0.7064 lr: 4.763e-07
Epoch 85 valid loss: 0.5905 acc: 0.7123
Epoch 86 train loss: 0.5928 acc: 0.7111 lr: 4.125e-07
Epoch 86 valid loss: 0.5902 acc: 0.7090
Epoch 87 train loss: 0.5926 acc: 0.7086 lr: 3.529e-07
Epoch 87 valid loss: 0.5904 acc: 0.7137
Saving Best
Epoch 88 train loss: 0.5939 acc: 0.7093 lr: 2.976e-07
Epoch 88 valid loss: 0.5908 acc: 0.7043
Epoch 89 train loss: 0.5932 acc: 0.7086 lr: 2.467e-07
Epoch 89 valid loss: 0.5888 acc: 0.7053
Epoch 90 train loss: 0.5924 acc: 0.7090 lr: 2.004e-07
Epoch 90 valid loss: 0.5900 acc: 0.7100
Epoch 91 train loss: 0.5923 acc: 0.7100 lr: 1.587e-07
Epoch 91 valid loss: 0.5878 acc: 0.7083
Epoch 92 train loss: 0.5934 acc: 0.7091 lr: 1.217e-07
Epoch 92 valid loss: 0.5903 acc: 0.7057
Epoch 93 train loss: 0.5923 acc: 0.7107 lr: 8.957e-08
Epoch 93 valid loss: 0.5909 acc: 0.7100
Epoch 94 train loss: 0.5926 acc: 0.7085 lr: 6.225e-08
Epoch 94 valid loss: 0.5897 acc: 0.7077
Epoch 95 train loss: 0.5920 acc: 0.7095 lr: 3.983e-08
Epoch 95 valid loss: 0.5910 acc: 0.7083
Epoch 96 train loss: 0.5913 acc: 0.7085 lr: 2.237e-08
Epoch 96 valid loss: 0.5894 acc: 0.7040
Epoch 97 train loss: 0.5927 acc: 0.7096 lr: 9.902e-09
Epoch 97 valid loss: 0.5910 acc: 0.7047
Epoch 98 train loss: 0.5929 acc: 0.7096 lr: 2.447e-09
Epoch 98 valid loss: 0.5887 acc: 0.7083
Epoch 99 train loss: 0.5931 acc: 0.7102 lr: 2.083e-11
Epoch 99 valid loss: 0.5886 acc: 0.7090
Training Time: 1645.455904006958
Training Peak Mem: 950.79296875
Training Params: 60544
Testing: synthetic/experiments/mix5/mix5_ensemble_best.pt
loss: tensor(0.6011, device='cuda:0')
acc: 0.6903333333333334
