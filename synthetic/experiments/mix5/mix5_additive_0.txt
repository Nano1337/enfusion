Train data: 14000
Valid data: 3000
Test data: 3000
initializing ensemble model
Epoch 0 train loss: 0.6828 acc: 0.5525 lr: 2.132e-07
Epoch 0 valid loss: 0.6839 acc: 0.5623
Saving Best
Epoch 1 train loss: 0.6811 acc: 0.5590 lr: 2.525e-07
Epoch 1 valid loss: 0.6818 acc: 0.5470
Epoch 2 train loss: 0.6804 acc: 0.5592 lr: 3.176e-07
Epoch 2 valid loss: 0.6792 acc: 0.5650
Saving Best
Epoch 3 train loss: 0.6785 acc: 0.5655 lr: 4.077e-07
Epoch 3 valid loss: 0.6782 acc: 0.5633
Epoch 4 train loss: 0.6761 acc: 0.5774 lr: 5.219e-07
Epoch 4 valid loss: 0.6762 acc: 0.5777
Saving Best
Epoch 5 train loss: 0.6732 acc: 0.5839 lr: 6.589e-07
Epoch 5 valid loss: 0.6724 acc: 0.5960
Saving Best
Epoch 6 train loss: 0.6705 acc: 0.5967 lr: 8.172e-07
Epoch 6 valid loss: 0.6668 acc: 0.6110
Saving Best
Epoch 7 train loss: 0.6651 acc: 0.6050 lr: 9.95e-07
Epoch 7 valid loss: 0.6616 acc: 0.6247
Saving Best
Epoch 8 train loss: 0.6603 acc: 0.6221 lr: 1.19e-06
Epoch 8 valid loss: 0.6570 acc: 0.6367
Saving Best
Epoch 9 train loss: 0.6555 acc: 0.6333 lr: 1.401e-06
Epoch 9 valid loss: 0.6514 acc: 0.6437
Saving Best
Epoch 10 train loss: 0.6491 acc: 0.6481 lr: 1.625e-06
Epoch 10 valid loss: 0.6427 acc: 0.6707
Saving Best
Epoch 11 train loss: 0.6429 acc: 0.6561 lr: 1.86e-06
Epoch 11 valid loss: 0.6364 acc: 0.6687
Epoch 12 train loss: 0.6358 acc: 0.6623 lr: 2.103e-06
Epoch 12 valid loss: 0.6306 acc: 0.6793
Saving Best
Epoch 13 train loss: 0.6294 acc: 0.6724 lr: 2.351e-06
Epoch 13 valid loss: 0.6246 acc: 0.6817
Saving Best
Epoch 14 train loss: 0.6226 acc: 0.6781 lr: 2.602e-06
Epoch 14 valid loss: 0.6194 acc: 0.6847
Saving Best
Epoch 15 train loss: 0.6153 acc: 0.6829 lr: 2.853e-06
Epoch 15 valid loss: 0.6104 acc: 0.6937
Saving Best
Epoch 16 train loss: 0.6083 acc: 0.6863 lr: 3.102e-06
Epoch 16 valid loss: 0.6039 acc: 0.6977
Saving Best
Epoch 17 train loss: 0.6021 acc: 0.6928 lr: 3.344e-06
Epoch 17 valid loss: 0.5973 acc: 0.6973
Epoch 18 train loss: 0.5958 acc: 0.6938 lr: 3.579e-06
Epoch 18 valid loss: 0.5902 acc: 0.7073
Saving Best
Epoch 19 train loss: 0.5911 acc: 0.6962 lr: 3.803e-06
Epoch 19 valid loss: 0.5852 acc: 0.7027
Epoch 20 train loss: 0.5852 acc: 0.6996 lr: 4.013e-06
Epoch 20 valid loss: 0.5794 acc: 0.7030
Epoch 21 train loss: 0.5819 acc: 0.7032 lr: 4.208e-06
Epoch 21 valid loss: 0.5773 acc: 0.7080
Saving Best
Epoch 22 train loss: 0.5754 acc: 0.7060 lr: 4.386e-06
Epoch 22 valid loss: 0.5743 acc: 0.7070
Epoch 23 train loss: 0.5729 acc: 0.7086 lr: 4.544e-06
Epoch 23 valid loss: 0.5703 acc: 0.7070
Epoch 24 train loss: 0.5690 acc: 0.7113 lr: 4.68e-06
Epoch 24 valid loss: 0.5640 acc: 0.7157
Saving Best
Epoch 25 train loss: 0.5677 acc: 0.7111 lr: 4.794e-06
Epoch 25 valid loss: 0.5615 acc: 0.7197
Saving Best
Epoch 26 train loss: 0.5638 acc: 0.7126 lr: 4.884e-06
Epoch 26 valid loss: 0.5611 acc: 0.7183
Epoch 27 train loss: 0.5617 acc: 0.7119 lr: 4.948e-06
Epoch 27 valid loss: 0.5626 acc: 0.7123
Epoch 28 train loss: 0.5613 acc: 0.7149 lr: 4.987e-06
Epoch 28 valid loss: 0.5608 acc: 0.7137
Epoch 29 train loss: 0.5573 acc: 0.7156 lr: 5e-06
Epoch 29 valid loss: 0.5573 acc: 0.7203
Saving Best
Epoch 30 train loss: 0.5579 acc: 0.7180 lr: 4.997e-06
Epoch 30 valid loss: 0.5554 acc: 0.7137
Epoch 31 train loss: 0.5565 acc: 0.7164 lr: 4.99e-06
Epoch 31 valid loss: 0.5569 acc: 0.7157
Epoch 32 train loss: 0.5572 acc: 0.7169 lr: 4.977e-06
Epoch 32 valid loss: 0.5546 acc: 0.7160
Epoch 33 train loss: 0.5570 acc: 0.7157 lr: 4.959e-06
Epoch 33 valid loss: 0.5534 acc: 0.7160
Epoch 34 train loss: 0.5556 acc: 0.7150 lr: 4.937e-06
Epoch 34 valid loss: 0.5538 acc: 0.7103
Epoch 35 train loss: 0.5535 acc: 0.7169 lr: 4.909e-06
Epoch 35 valid loss: 0.5522 acc: 0.7147
Epoch 36 train loss: 0.5557 acc: 0.7150 lr: 4.877e-06
Epoch 36 valid loss: 0.5511 acc: 0.7127
Epoch 37 train loss: 0.5559 acc: 0.7171 lr: 4.84e-06
Epoch 37 valid loss: 0.5513 acc: 0.7143
Epoch 38 train loss: 0.5549 acc: 0.7155 lr: 4.798e-06
Epoch 38 valid loss: 0.5494 acc: 0.7163
Epoch 39 train loss: 0.5553 acc: 0.7171 lr: 4.752e-06
Epoch 39 valid loss: 0.5519 acc: 0.7177
Epoch 40 train loss: 0.5547 acc: 0.7172 lr: 4.701e-06
Epoch 40 valid loss: 0.5519 acc: 0.7113
Epoch 41 train loss: 0.5545 acc: 0.7145 lr: 4.645e-06
Epoch 41 valid loss: 0.5511 acc: 0.7167
Epoch 42 train loss: 0.5544 acc: 0.7185 lr: 4.585e-06
Epoch 42 valid loss: 0.5505 acc: 0.7150
Epoch 43 train loss: 0.5543 acc: 0.7178 lr: 4.521e-06
Epoch 43 valid loss: 0.5558 acc: 0.7110
Epoch 44 train loss: 0.5520 acc: 0.7147 lr: 4.453e-06
Epoch 44 valid loss: 0.5514 acc: 0.7130
Epoch 45 train loss: 0.5528 acc: 0.7203 lr: 4.381e-06
Epoch 45 valid loss: 0.5527 acc: 0.7123
Epoch 46 train loss: 0.5526 acc: 0.7164 lr: 4.306e-06
Epoch 46 valid loss: 0.5488 acc: 0.7120
Epoch 47 train loss: 0.5537 acc: 0.7211 lr: 4.226e-06
Epoch 47 valid loss: 0.5506 acc: 0.7200
Epoch 48 train loss: 0.5541 acc: 0.7195 lr: 4.143e-06
Epoch 48 valid loss: 0.5505 acc: 0.7167
Epoch 49 train loss: 0.5517 acc: 0.7174 lr: 4.057e-06
Epoch 49 valid loss: 0.5500 acc: 0.7107
Epoch 50 train loss: 0.5529 acc: 0.7188 lr: 3.968e-06
Epoch 50 valid loss: 0.5515 acc: 0.7110
Epoch 51 train loss: 0.5501 acc: 0.7175 lr: 3.876e-06
Epoch 51 valid loss: 0.5538 acc: 0.7153
Epoch 52 train loss: 0.5533 acc: 0.7169 lr: 3.781e-06
Epoch 52 valid loss: 0.5541 acc: 0.7167
Epoch 53 train loss: 0.5558 acc: 0.7161 lr: 3.683e-06
Epoch 53 valid loss: 0.5552 acc: 0.7083
Epoch 54 train loss: 0.5526 acc: 0.7194 lr: 3.583e-06
Epoch 54 valid loss: 0.5523 acc: 0.7163
Epoch 55 train loss: 0.5525 acc: 0.7167 lr: 3.481e-06
Epoch 55 valid loss: 0.5507 acc: 0.7147
Epoch 56 train loss: 0.5532 acc: 0.7208 lr: 3.377e-06
Epoch 56 valid loss: 0.5520 acc: 0.7153
Epoch 57 train loss: 0.5520 acc: 0.7201 lr: 3.271e-06
Epoch 57 valid loss: 0.5500 acc: 0.7173
Epoch 58 train loss: 0.5512 acc: 0.7180 lr: 3.163e-06
Epoch 58 valid loss: 0.5566 acc: 0.7103
Epoch 59 train loss: 0.5530 acc: 0.7184 lr: 3.054e-06
Epoch 59 valid loss: 0.5512 acc: 0.7147
Epoch 60 train loss: 0.5519 acc: 0.7179 lr: 2.944e-06
Epoch 60 valid loss: 0.5527 acc: 0.7163
Epoch 61 train loss: 0.5541 acc: 0.7174 lr: 2.834e-06
Epoch 61 valid loss: 0.5513 acc: 0.7147
Epoch 62 train loss: 0.5519 acc: 0.7192 lr: 2.722e-06
Epoch 62 valid loss: 0.5510 acc: 0.7137
Epoch 63 train loss: 0.5525 acc: 0.7175 lr: 2.61e-06
Epoch 63 valid loss: 0.5541 acc: 0.7140
Epoch 64 train loss: 0.5536 acc: 0.7184 lr: 2.498e-06
Epoch 64 valid loss: 0.5551 acc: 0.7140
Epoch 65 train loss: 0.5529 acc: 0.7201 lr: 2.386e-06
Epoch 65 valid loss: 0.5476 acc: 0.7180
Epoch 66 train loss: 0.5522 acc: 0.7191 lr: 2.274e-06
Epoch 66 valid loss: 0.5518 acc: 0.7183
Epoch 67 train loss: 0.5533 acc: 0.7181 lr: 2.162e-06
Epoch 67 valid loss: 0.5491 acc: 0.7140
Epoch 68 train loss: 0.5526 acc: 0.7193 lr: 2.052e-06
Epoch 68 valid loss: 0.5501 acc: 0.7177
Epoch 69 train loss: 0.5519 acc: 0.7194 lr: 1.942e-06
Epoch 69 valid loss: 0.5519 acc: 0.7113
Epoch 70 train loss: 0.5520 acc: 0.7197 lr: 1.833e-06
Epoch 70 valid loss: 0.5489 acc: 0.7163
Epoch 71 train loss: 0.5526 acc: 0.7174 lr: 1.726e-06
Epoch 71 valid loss: 0.5518 acc: 0.7193
Epoch 72 train loss: 0.5526 acc: 0.7171 lr: 1.62e-06
Epoch 72 valid loss: 0.5482 acc: 0.7137
Epoch 73 train loss: 0.5506 acc: 0.7166 lr: 1.516e-06
Epoch 73 valid loss: 0.5502 acc: 0.7163
Epoch 74 train loss: 0.5505 acc: 0.7204 lr: 1.413e-06
Epoch 74 valid loss: 0.5501 acc: 0.7167
Epoch 75 train loss: 0.5515 acc: 0.7174 lr: 1.314e-06
Epoch 75 valid loss: 0.5509 acc: 0.7157
Epoch 76 train loss: 0.5522 acc: 0.7182 lr: 1.216e-06
Epoch 76 valid loss: 0.5528 acc: 0.7117
Epoch 77 train loss: 0.5524 acc: 0.7196 lr: 1.121e-06
Epoch 77 valid loss: 0.5481 acc: 0.7143
Epoch 78 train loss: 0.5518 acc: 0.7169 lr: 1.029e-06
Epoch 78 valid loss: 0.5517 acc: 0.7117
Epoch 79 train loss: 0.5526 acc: 0.7196 lr: 9.397e-07
Epoch 79 valid loss: 0.5524 acc: 0.7143
Epoch 80 train loss: 0.5540 acc: 0.7176 lr: 8.536e-07
Epoch 80 valid loss: 0.5483 acc: 0.7183
Epoch 81 train loss: 0.5524 acc: 0.7171 lr: 7.709e-07
Epoch 81 valid loss: 0.5524 acc: 0.7153
Epoch 82 train loss: 0.5519 acc: 0.7161 lr: 6.916e-07
Epoch 82 valid loss: 0.5503 acc: 0.7133
Epoch 83 train loss: 0.5523 acc: 0.7181 lr: 6.16e-07
Epoch 83 valid loss: 0.5506 acc: 0.7170
Epoch 84 train loss: 0.5505 acc: 0.7169 lr: 5.442e-07
Epoch 84 valid loss: 0.5479 acc: 0.7190
Epoch 85 train loss: 0.5526 acc: 0.7180 lr: 4.763e-07
Epoch 85 valid loss: 0.5518 acc: 0.7213
Saving Best
Epoch 86 train loss: 0.5521 acc: 0.7188 lr: 4.125e-07
Epoch 86 valid loss: 0.5491 acc: 0.7170
Epoch 87 train loss: 0.5516 acc: 0.7156 lr: 3.529e-07
Epoch 87 valid loss: 0.5512 acc: 0.7160
Epoch 88 train loss: 0.5523 acc: 0.7181 lr: 2.976e-07
Epoch 88 valid loss: 0.5508 acc: 0.7130
Epoch 89 train loss: 0.5522 acc: 0.7189 lr: 2.467e-07
Epoch 89 valid loss: 0.5509 acc: 0.7150
Epoch 90 train loss: 0.5513 acc: 0.7198 lr: 2.004e-07
Epoch 90 valid loss: 0.5502 acc: 0.7203
Epoch 91 train loss: 0.5507 acc: 0.7192 lr: 1.587e-07
Epoch 91 valid loss: 0.5471 acc: 0.7220
Saving Best
Epoch 92 train loss: 0.5526 acc: 0.7160 lr: 1.217e-07
Epoch 92 valid loss: 0.5508 acc: 0.7143
Epoch 93 train loss: 0.5509 acc: 0.7199 lr: 8.957e-08
Epoch 93 valid loss: 0.5502 acc: 0.7210
Epoch 94 train loss: 0.5518 acc: 0.7190 lr: 6.225e-08
Epoch 94 valid loss: 0.5499 acc: 0.7190
Epoch 95 train loss: 0.5511 acc: 0.7192 lr: 3.983e-08
Epoch 95 valid loss: 0.5518 acc: 0.7163
Epoch 96 train loss: 0.5506 acc: 0.7176 lr: 2.237e-08
Epoch 96 valid loss: 0.5489 acc: 0.7170
Epoch 97 train loss: 0.5517 acc: 0.7170 lr: 9.902e-09
Epoch 97 valid loss: 0.5536 acc: 0.7143
Epoch 98 train loss: 0.5517 acc: 0.7183 lr: 2.447e-09
Epoch 98 valid loss: 0.5477 acc: 0.7177
Epoch 99 train loss: 0.5515 acc: 0.7193 lr: 2.083e-11
Epoch 99 valid loss: 0.5500 acc: 0.7150
Training Time: 1641.5679948329926
Training Peak Mem: 940.390625
Training Params: 60544
Testing: synthetic/experiments/mix5/mix5_additive_best.pt
loss: tensor(0.5631, device='cuda:0')
acc: 0.7103333333333334
